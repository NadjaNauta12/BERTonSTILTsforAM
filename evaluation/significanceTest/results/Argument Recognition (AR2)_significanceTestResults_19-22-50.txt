Argument Recognition (AR2) - Inter_Training GM >> UGIP - Best Model ACIL
Bootstraps B	50
Sample_size	112
delta observed	0.04576450959318165
P-value	0.06
	bootstrap_f1_STS	bootstrap_f1_STILT	delta	teststatistic2delta	teststatisticsimple
0	0.17899863627508278	0.23961267605633801	0.060614039781255236	0	1
1	0.18835714285714283	0.21624026696329257	0.027883124106149737	0	1
2	0.14972067039106143	0.17428243398392654	0.024561763592865105	0	1
3	0.13173652694610777	0.23038839095177127	0.0986518640056635	1	1
4	0.1632966299632966	0.21445378151260502	0.051157151549308416	0	1
5	0.18437869822485206	0.24056056056056058	0.056181862335708516	0	1
6	0.17357142857142857	0.2085106382978723	0.03493920972644374	0	1
7	0.17177225340817964	0.23681069467653376	0.06503844126835412	0	1
8	0.1744672531769306	0.21841269841269845	0.04394544523576785	0	1
9	0.14429482636428065	0.2421333333333333	0.09783850696905266	1	1
10	0.16311188811188812	0.21206896551724136	0.04895707740535324	0	1
11	0.16568144499178983	0.20901639344262296	0.04333494845083313	0	1
12	0.16021220159151195	0.23123123123123124	0.07101902963971929	0	1
13	0.20333704115684098	0.2391582422116773	0.03582120105483633	0	1
14	0.15773081201334818	0.22490892531876136	0.06717811330541318	0	1
15	0.1684965100924354	0.2016844469399214	0.033187936847486	0	1
16	0.14340909090909093	0.17372195234790655	0.03031286143881562	0	1
17	0.15565356856455492	0.2088529474356246	0.05319937887106968	0	1
18	0.15384615384615383	0.19806763285024154	0.04422147900408771	0	1
19	0.14776070611310885	0.24008648648648645	0.0923257803733776	1	1
20	0.1936723163841808	0.24642857142857144	0.05275625504439063	0	1
21	0.17276166456494324	0.2087768440709617	0.03601517950601846	0	1
22	0.14104046242774565	0.21213235294117644	0.07109189051343079	0	1
23	0.17085271317829456	0.21025465342012106	0.0394019402418265	0	1
24	0.178375470683163	0.21060606060606063	0.03223058992289762	0	1
25	0.1715151515151515	0.22879719051799827	0.05728203900284676	0	1
26	0.15446371226718053	0.20938673341677094	0.05492302114959041	0	1
27	0.15873721654068476	0.2226356589147287	0.06389844237404393	0	1
28	0.17126148705096075	0.2138644366197183	0.04260294956875754	0	1
29	0.1706558485463151	0.21035249285487456	0.03969664430855946	0	1
30	0.13801169590643275	0.21127076784912435	0.0732590719426916	0	1
31	0.18547687861271678	0.2134977287475665	0.02802085013484973	0	1
32	0.20418834200346808	0.2333614864864865	0.029173144483018415	0	1
33	0.21277445109780438	0.22212806026365345	0.00935360916584907	0	1
34	0.16819000819000818	0.2418477690288714	0.07365776083886322	0	1
35	0.18229965156794425	0.22546306152863532	0.04316340996069107	0	1
36	0.16514991181657845	0.21363737983456293	0.04848746801798448	0	1
37	0.14104046242774565	0.2307406547480845	0.08970019232033885	0	1
38	0.1521155830753354	0.2221311475409836	0.07001556446564819	0	1
39	0.15657870791628753	0.22659829059829056	0.07001958268200303	0	1
40	0.13075204765450482	0.20723774622079705	0.07648569856629223	0	1
41	0.14870667793744716	0.21174089068825905	0.06303421275081189	0	1
42	0.1450301204819277	0.21260532524435458	0.06757520476242687	0	1
43	0.1647058823529412	0.21107142857142858	0.046365546218487375	0	1
44	0.1483296961557831	0.21520361990950226	0.06687392375371917	0	1
45	0.17102564102564105	0.23807813201616526	0.06705249099052421	0	1
46	0.15724508050089445	0.20333333333333337	0.04608825283243892	0	1
47	0.19095607235142117	0.21937441643323993	0.028418344081818758	0	1
48	0.16654384672070746	0.2155809103177524	0.04903706359704493	0	1
49	0.17231968810916182	0.1750356164383562	0.0027159283291943725	0	1
